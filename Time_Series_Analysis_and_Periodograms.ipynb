{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Week 12: Time-series analysis and Periodograms\n",
    "\n",
    "This Workbook is a short instroduction to using the periodogram code. You can use the GLS code for your assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#from GLS import GLS as GLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a code for that will generate the Generalised Lomb Scargle Periodogram. \n",
    "\n",
    "**Exercise 1:** Look through the code and annotate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Routine to calculate the Generalised Lomb Scargle (see Zechmeister & Kuster 2009).\n",
    "#Inputs:\n",
    "# t - time \n",
    "# y - data values\n",
    "# sig - uncertainties on y\n",
    "# period - array containing the periods on which the periodogram should be calculated.\n",
    "#\n",
    "#Outputs:\n",
    "# p_om - the periodogram\n",
    "# a_om - the amplitude of the cosine term \n",
    "# b_om - the amplitude of the sine term\n",
    "# Note: total amplitude is sqrt(a_om+b_om)\n",
    "def GLS(t,y,sig,period=np.logspace(-1.,1.4,int(1e5))):\n",
    "    W=np.sum(1./sig**2)\n",
    "    w=1./W * 1./sig**2\n",
    "\n",
    "    Y=np.sum(w*y)\n",
    "    YYh=np.sum(w*y*y)\n",
    "    p_om=np.zeros(period.shape[0])\n",
    "    a_om=np.zeros(period.shape[0])\n",
    "    b_om=np.zeros(period.shape[0])\n",
    "    for i,P in enumerate(period):\n",
    "        omt=2.*np.pi*t/P\n",
    "        cos_omt=np.cos(omt)\n",
    "        sin_omt=np.sin(omt)\n",
    "        C=np.sum(w*cos_omt)\n",
    "        S=np.sum(w*sin_omt)\n",
    "        YCh=np.sum(w*y*cos_omt)\n",
    "        YSh=np.sum(w*y*sin_omt)\n",
    "        CCh=np.sum(w*cos_omt*cos_omt)\n",
    "        SSh=np.sum(w*sin_omt*sin_omt)\n",
    "        CSh=np.sum(w*cos_omt*sin_omt)\n",
    "        YY=YYh-Y*Y\n",
    "        YC=YCh-Y*C\n",
    "        YS=YSh-Y*S\n",
    "        CC=CCh-C*C\n",
    "        SS=SSh-S*S\n",
    "        CS=CSh-C*S\n",
    "        D=CC*SS-CS**2\n",
    "        p_om[i]=(SS*YC**2+CC*YS**2-2*CS*YC*YS)/(YY*D)\n",
    "        a_om[i]=(YC*SS-YS*CS)/D\n",
    "        b_om[i]=(YS*CC-YC*CS)/D\n",
    "    return p_om,a_om,b_om"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate some a simple sinusoidal curve both with two different noise levels to test the GLS code. The sinusoidal curve contains a phase offset of pi/4 (45 degrees) and is uniformly sampled (if you want, you can also test the FFT method on this data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=np.arange(0,30.,0.01)\n",
    "Per=4.5\n",
    "mdl=np.sin(2.*np.pi*t/Per+np.pi/4)\n",
    "mdl_noise1=mdl+np.random.normal(0.,0.1,t.shape[0])\n",
    "mdl_noise2=mdl+np.random.normal(0.,5.,t.shape[0])\n",
    "sig1=t*0.+0.1\n",
    "sig2=t*0.+5.\n",
    "plt.plot(t,mdl_noise2,'k.')\n",
    "plt.plot(t,mdl,linewidth=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:** Calculate the periodogram both for the model with and without noise. For a useful period grid, you want to use something that is uniform in frequency (or at the very least uniform in logspacing, using np.logspace). The longest period/lowest frequency that you want to use should equal the total timespan / 2 (for period) or the 1/(2 time the timespan) (for the frequency). You also want to oversample the periods to get a nice smooth periodogram. You can use the P below as a starting point.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P=np.logspace(-1.3,np.log10(30./2.),int(1e5))\n",
    "p_om,a_om,b_om=GLS(t,mdl_noise2,sig2,P)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** After calculating the periodogram for the two noise-levels, try to use the periodogram to find the best fit model for the strongest period. Subtract this model from the data and reconstruct the periodogram. The model should be given by a($\\omega_{best})$cos($\\omega_{best}t$)+b($\\omega_{best})$sin($\\omega_{best}t$))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now generate some non-uniformly sampled data. First, we use a random number generator to select about 1 in 5 points from the overall sample. We sort this array, and only select the unique values, discarding any duplicates. Finally, we us np.hstack to cut chuncks out of the idx array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a random sampling of 1/5th the points and sort the array\n",
    "time_sampling=np.random.randint(0,t.shape[0],int((t.shape[0]/5)))\n",
    "time_sampling.sort()\n",
    "\n",
    "#Discard any duplicate points\n",
    "idx=np.unique(time_sampling)\n",
    "\n",
    "#Cut out two larger chunks, in this case from 70 to 110 and 220 to 240\n",
    "idx=np.hstack( (idx[0:70],idx[110:220],idx[240:]))\n",
    "\n",
    "#define the new time and data & sigma arrays.\n",
    "t_sample=t[idx].copy()\n",
    "mdl_noise2_sample=mdl_noise2[idx].copy()\n",
    "sig2_sample=sig2[idx].copy()\n",
    "\n",
    "plt.plot(t_sample,mdl_noise2_sample,'k.')\n",
    "plt.plot(t,mdl,linewidth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4** Calculate the periodogram for this dataset with gaps in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the impact of the sampling on the data, we can simulate pure white noise with similar noise properties as the data, and recreate the periodogram. Any peaks that are in the same place for the white noise simulations and the real data are likely due to the way we sampled the data, and not due to any intrinsic periodicity that we are interested in. Note that although the locations of the peak in the white noise data set can match those in the data, their amplitudes will be different and cannot be directly compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a white-noise dataset and make a periodogram\n",
    "mockdata=np.random.normal(t_sample*0.,sig2_sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5:** Calculate the periodogram for the white-noise data and compare it to the one for the simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's look at a more complicated model with multiple frequencies and phase shifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Per1=1.2\n",
    "Per2=6.265\n",
    "Per3=11.\n",
    "mdl=np.sin(2.*np.pi*t/Per1+np.pi/4)+0.75*np.sin(2.*np.pi*t/Per2+np.pi/8)-1.3*np.sin(2.*np.pi*t/Per3+3*np.pi/4)\n",
    "mdl_noise2=mdl+np.random.normal(0.,5.,t.shape[0])\n",
    "t_sample=t[idx].copy()\n",
    "mdl_noise2_sample=mdl_noise2[idx].copy()\n",
    "sig2_sample=sig2[idx].copy()\n",
    "\n",
    "plt.plot(t_sample,mdl_noise2_sample,'k.')\n",
    "plt.plot(t,mdl,linewidth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6:** Create the periodogram, and then try to subtract the strongest peak. Repeat this, until you think that you are no longer removing valid peaks from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
